# @package _global_

defaults:
  - m2
model:
  hidden_size: 512
dataset:
  scale_ratio: 1.0
  falcon_m2:
    respect_trial_boundaries: False
    chop_size_ms: 500
  augmentations: ['explicit_crop_time']
train:
  max_batch_size: 256
  batch_size: 64
effective_bsz: 128
sweep_cfg: chop_coarse_500ms